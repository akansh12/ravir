{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7ce58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "# from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "from model_seg_ravir_net import segRAVIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a53b72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train_images = Path(\"/scratch/scratch6/akansh12/ravir_data/RAVIR Dataset/train/training_images/\")\n",
    "path2train_mask = Path(\"/scratch/scratch6/akansh12/ravir_data/ravir/data/training_images_masks/\")\n",
    "path2test_images = Path(\"/scratch/scratch6/akansh12/ravir_data/RAVIR Dataset/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aa774f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ravir_dataset():\n",
    "    def __init__(self, img_dir, mask_dir, transform = None, data_type = 'train'):\n",
    "        self.segs_dir = None\n",
    "        if data_type == 'train':\n",
    "            self.images_dir = sorted(glob(os.path.join(path2train_images, \"*.png\")))[:19]\n",
    "            self.segs_dir = sorted(glob(os.path.join(path2train_mask, \"*.npy\")))[:19]\n",
    "        if data_type == \"val\":\n",
    "            self.images_dir = sorted(glob(os.path.join(path2train_images, \"*.png\")))[19:]\n",
    "            self.segs_dir = sorted(glob(os.path.join(path2train_mask, \"*.npy\")))[19:]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = np.array(Image.open(self.images_dir[idx])).astype('uint8')\n",
    "        \n",
    "        if self.segs_dir is not None:\n",
    "            seg = np.load(self.segs_dir[idx]).astype('uint8')\n",
    "            img = self.transform(img)\n",
    "            return img, torch.FloatTensor(seg)\n",
    "        else:\n",
    "            img = self.transform(img)\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08e67ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ravir_dataset(path2train_images, path2train_mask, transform=transforms.ToTensor(), data_type='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10225591",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_dataset:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7466fa35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e82a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a628486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b99d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf0d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404abc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb8bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4805b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e11f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((4,1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78a06fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38baffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = segRAVIR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b229b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, x_hat = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5820835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 128, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5183e79e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'monai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26433/3340227838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'monai'"
     ]
    }
   ],
   "source": [
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416d838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
